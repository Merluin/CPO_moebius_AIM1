---
title: "**Mapping the Perception-space of Facial Expressions (Moebius Participants)**"
subtitle: "Supplementary Materials"
author: 
  - "Thomas Quettier"
  - "Paola Sessa"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
    highlight: pygments
bibliography: ["../files/references.bib"]
header-includes:
  - \AddToHook{cmd/section/before}{\clearpage}
  - \usepackage{titling}
  - \setcounter{table}{0} 
  - \renewcommand*{\thetable}{S\arabic{table}}
  - \setcounter{figure}{0} 
  - \renewcommand*{\thefigure}{S\arabic{figure}}
  - \usepackage{lscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \usepackage[nottoc]{tocbibind}

---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center",
                      fig.retina = 2,
                      dev = "pdf")
```

```{r packages, cache=FALSE}
devtools::load_all()
library(here)
library(magrittr)
library(tidyr)
library(dplyr)
library(kableExtra)
library(flextable)
library(ggplot2)
library(sjPlot)
library(XML)
library(rlist)
library(janitor)
```

```{r data}
circular <- readRDS(here("objects", "circular_objects.rds"))
intensity <- readRDS(here("objects", "intensity_objects.rds"))
plots <- readRDS(here("objects", "paper_plots.rds"))
tables <- readRDS(here("objects", "paper_tables.rds"))
dat <- readRDS(here("data", "dataset_valid.rds"))
emo_coords <- readRDS(here("objects", "emo_coords.rds"))
```

```{r analysis-setup}
captions <- get_captions(file = here("docs", "files", "supplementary-captions.txt"))
```

```{r functions}
tidy_prior <- function(data){
  data %>% 
    select(-source, -group, -resp, -nlpar, -lb, -ub)
}

qtab <- function(data, max_width = 6){
  data %>% 
    flextable() %>% 
    autofit() %>% 
    theme_vanilla() %>% 
    fit_to_width(max_width = max_width)
}

get_chunk_label <- function(){
  knitr::opts_current$get("label")
}

theme_paper <- function(font_size = 25){
  cowplot::theme_minimal_grid(font_size = font_size)
}

newpage <- function(){
  cat("\\newpage\n")
}
```

# General approach

The Geneva Emotion Wheel [GEW; @Scherer2005-nc] allows having an intuitive and informative way to collect participants' responses in a facial expression perception task. Specifically, in a single measurement is possible to have information about the facial expression *category* (i.e., the response angle around the circle) and *intensity* (i.e., the distance from the center).

## Facial expression category

In order to measure the response angle for each trial we transformed Cartesian coordinates ($(x_i, y_i)$) into polar coordinates ($(r_i, \theta_i)$) as in Equation \@ref(eq:coord-polar).

\begin{equation}
\theta_{ij} = tan^{-1}(\frac{y_{ij}}{x_{ij}})
(\#eq:coord-polar)
\end{equation}

In this way we have the *pressed angle* for each trial. Given that each emotion has an absolute location on the GEW, we calculated a *position-free* index of performance computing the difference between the *pressed angle* and the *ideal angle* (i.e., the GEW location of the presented emotion).

Then we calculated the *ideal* angle for each presented emotion, in the middle of each wheel circle. To obtain a measure comparable between emotion, we calculated the angular difference between the *ideal* and the pressed angle using the Equation \@ref(eq:ang-diff)

\begin{equation}
Bias = ((ideal - pressed) + 180) \mod 360 - 180
(\#eq:ang-diff)
\end{equation}

This new measure (*bias*) has several advantages. Despite each emotion have a different location within the wheel, each response is now expressed in a position-free metric. The *bias* is centered on 0 if there is no response tendency away from the *ideal* value. Otherwise, a systematic shift would move the circular mean away from 0, clockwise (positive values) or anticlockwise (negative values). In circular statistics, *bias* is also called *angular error* and is deffined as the difference between a reference angle and the subject's response. Other than the circular mean, also the spread on the circle (i.e., *uncertainty* or resultant length) is an important performance measure. The *bias* and the *uncertainty* can be considered independent measures. The circular variance ranges between 0 (no *uncertainty*) to 1 (maximum *uncertainty*) and is defined as 1- mean resultant length. 

Given the periodicity of circular data, we cannot use standard statistical modeling tools [@Cremers2018-gr; @Cremers2018-in]. There are different ways to model circular data [see @Cremers2018-gr for an overview]. 


## Perceived Intensity

The emotion *intensity* is expressed as the difference from the center of the GEW. Values close or far from the center represent respectively neutral and high facial expression intensity. We calculated the *intensity* for each trial as the *euclidean distance* between the *center* and the *pressed location*. Given that the GEW has been centered (i.e., the center has coordinates $x = 0,y = 0$), the distance from the center is calculated as Equation \@ref(eq:euclidean).

\begin{equation}
I_{ij} = \sqrt{x^2 + y^2} 
(\#eq:euclidean)
\end{equation}

## Statistical models

For the response angle (i.e., *bias* and *uncertainty*) we decided to use a generalized linear mixed-effect model using bpnreg R package (v2.0.2; Jolien and Cremers 2021). It is based on the 'embedding' approach to circular modelling and makes use of the projected normal distribution. Its estimation method is a Bayesian MCMC sampler. Further technical details can be found in Cremers, Mulder & Klugkist (2018) and Cremers & Klugkist (2018).


### `bpnme`

We fitted our models using the `bpnreg` package. According to different models the `bpnme` setup could be different in terms of `backend`, number of `iterations` and `chains` and the parallelization approach. The general approach for `bias/uncertainty` models is the following:

```{r circular-brms, eval = FALSE, echo = TRUE}

# the scale-location specification
form <- bf(theta_cen ~ ... + (1|id), 
           kappa ~ ... + (1|id))

bpnreg(formula, # model formula
       data = dat_neutral,
       its = iter,
       burn = burns,
       n.lag = n.lags,
       seed = seeds)
```

For the `perceived intensity`

```{r perceived-intensity-brms, eval = FALSE, echo = TRUE}

lmer(int ~ ... + (1|id),
    data = data,
    prior = priors,
    family = gaussian(),
    chains = 15,
    cores = 15,
    iter = 4000,
    save_pars = save_pars(all = TRUE),
    sample_prior = "yes",
    seed = 2022)
```

For the `perceived intensity` models we use the same approach as the main models given the simpler fitting process.

## Raw data

The figure \@ref(fig:gew-emotions) represents all participants' responses for each experimental condition, directly plotted on the GEW. The figure \@ref(fig:gew-legend-neutral) represents the GEW legend and the responses to the neutral condition.

```{r gew-legend-neutral, fig.cap=captions[get_chunk_label()], fig.width=12, out.width="100%"}

bg <- magick::image_read(here("files", "gew_low_res.png"))
bg <- magick::image_modulate(bg, brightness = 80)

gew_legend <- emo_coords %>%   
  mutate(mask = "Legend",
         flip = ifelse(x_emo < 0, degree_emo + 180, degree_emo),
         emotion = stringr::str_to_title(emotion)) %>% 
  ggplot() +
  ggpubr::background_image(bg) +
  geom_text(aes(x = x_emo*0.75, y = y_emo*0.75, 
                label = emotion, 
                angle = flip),
            size = 6, fontface = "bold",
            check_overlap = TRUE) +
  facet_grid(. ~ mask) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        strip.text.x = element_text(size = 20, face = "bold"),
        strip.text.y = element_text(size = 20, face = "bold"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white", color = NA)) +
  coord_fixed(xlim = c(-300, 300), ylim = c(-300, 300))

dat_plot <- dat %>% 
  dplyr::select(Pt.group,Wheel.task,emotion,Wheel.name, Video.intensity, x_cen, y_cen) %>% 
  mutate( intensity = stringr::str_to_title(Video.intensity),
          emotion = stringr::str_to_title(emotion),
          emotion = ifelse(emotion == "Neutrality", "Neutral", emotion),
          emotion = factor(emotion),
          emotion = forcats::fct_relevel(emotion, "Neutral"))

neutral_plot <- dat_plot %>% 
  filter(emotion == "Neutral") %>% 
  ggplot(aes(x = x_cen, y = y_cen)) +
  ggpubr::background_image(bg) +
  geom_point(alpha = 0.5, show.legend = FALSE, size = 3) +
  ggh4x::facet_nested(Video.intensity ~ emotion, switch="y") +
  coord_fixed(xlim = c(-300, 300), ylim = c(-300, 300)) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 20, face = "bold"),
        strip.text.y = element_text(size = 20, face = "bold"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white", color = NA))

cowplot::plot_grid(neutral_plot, gew_legend, labels = "AUTO")
```

\newpage
\blandscape

```{r gew-emotions, fig.cap=captions[get_chunk_label()], fig.width=13, fig.height=13, out.width="100%"}
plots$plot_gew_emotions
```

\elandscape

# Fitted Models{#fitted-models}

Table \@ref(tab:tab-info-models) depicts all fitted models with comparison criteria for *bias* and *uncertainty*. 
We performed model selection for our analysis of circular data using three criteria: the log pointwise predictive density (lppd) [1], the deviance information criterion (DIC) [2], and the Watanabe-Akaike information criterion (WAIC) [3]. These criteria enable us to evaluate the goodness of fit and model complexity, facilitating the selection of the most suitable model.

\blandscape

```{r tab-info-models}
fit <- readRDS(here("models","theta","modelcomparison_theta.rds"))

fit %>%
    flextable() %>% 
    colformat_double(digits = 2) %>% 
    autofit() 
```

\elandscape

In the next section we presented all fitted models using the same approach:

- the model name (the same name as the R object)
- model output

\newpage

## Bias

```{r circular-tables, results='asis'}

bias<-readRDS(here("models","theta","CircularMean.fit6.rds"))


    # selected models
    cat(paste("###", paste0("Model6; theta ~ ", as.character(bias$mm$pred.I[3])), "\n"))

    
    # Fixed Effects
    cat(paste("####", "Fixed Effects", "\n"))
    bias$lin.coef.I %>%
      data.frame() %>% 
      qtab() %>% 
      set_caption(caption = "") %>% 
      flextable_to_rmd()
    
    # Circular Coefficients
    cat(paste("####", "Model", "\n"))
    bias$circ.coef %>% 
      data.frame() %>% 
      dplyr::select(contains("SAM"))%>%
      qtab() %>% 
      colformat_double(digits = 5) %>% 
      set_caption("") %>% 
      flextable_to_rmd()
    newpage()

```

## Uncertainty

```{r circular-tables_uncertainty, results='asis'}
bias<-readRDS(here("models","theta","Rho_Mean.fit6.rds"))
sum<-summary(bias, show.df = TRUE)

    # selected models
    cat(paste("###","Model6; kappa ~ emotion + intensity + group + (1|subject)", "\n"))

    x<-tab_model(bias, file = "temp.html")
    readHTMLTable(here("docs","supplementary","temp.html"))
    
    
tables <- list.clean(readHTMLTable(here("docs","supplementary","temp.html")), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()
tables2[is.na(tables2)] <- ""

knitr::kable(tables2, format = "pipe")


```

\newpage

## Perceived intensity

```{r intensity-tables, results='asis'}
bias<-readRDS(here("models","intensity","magnitude_mean.fit6.rds"))
sum<-summary(bias, show.df = TRUE)

    # selected models
    cat(paste("###","Model6; magnitude ~ emotion * intensity * group * correct + (1|subject)", "\n"))

     x<-tab_model(bias, file = "temp.html")
    readHTMLTable(here("docs","supplementary","temp.html"))
    
    
tables <- list.clean(readHTMLTable(here("docs","supplementary","temp.html")), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()
tables2[is.na(tables2)] <- ""

knitr::kable(tables2, format = "pipe")
```

# Suggestions for meta-analysis

In this section, there are some suggestions for including these results into a meta-analysis. Firstly, if the presented results are not sufficient, the online OSF repository (https://osf.io/e2kcw/) contains raw data to compute all relevant measures. In general, for Bayesian models, each parameter or posterior contrast has a full posterior probability. This makes the computation of new measures (e.g., standardized effect sizes) and standard errors relatively easy. The only difference from standard calculations is that each new measure will have a full posterior distribution. These new distributions can be summarized (e.g., using the median) and used for the meta-analytic model.

## Bias

To our knowledge, for the *bias*, there is no straightforward standardized effect size measure to compute, especially for a meta-analytic model. A possibility is using a general index of overlap between two posterior distributions (e.g., for a specific post-hoc contrast) as proposed by Pastore and CalcagnÃ¬ [-@Pastore2019-tq]. However, the meta-analytic comparison with standard effect sizes index is not straightforward.

## Uncertainty

For the *uncertainty* it is possible to use directly the values from the posterior contrasts. The *uncertainty* (i.e., *circular variance*) is expressed on a scale from 0 to 1 (similar to a probability). All posterior contrasts can be interpreted as probability ratios and odds ratios. Also, the standard error can be calculated as the standard deviation of the posterior distribution. Furthermore, it is also possible to convert from odds ratio (or similar measures) to other effect size indexes (e.g., Cohen's $d$, see https://easystats.github.io/effectsize/reference/d_to_r.html).

## Perceived Intensity

For the perceived intensity it is possible to use a standard Cohen's $d$ measure. The only general caveat about calculating a Cohen's $d$ with multilevel models concerns which standard deviation(s) to use [@Brysbaert2018-wp; @Westfall2014-im]

# References

\end{document}